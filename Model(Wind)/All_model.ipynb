{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36dfb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "df = pd.read_csv(r\"D:\\DAU\\ASSIGNMENT\\FOML ASSIGN\\PROJ\\SAHIL\\India_Renewable_Energy_MASTER_DATASET_Calculated.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = pd.get_dummies(df, columns=['Season'], prefix='Season')\n",
    "df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Lag Features\n",
    "df['PS_lag_1'] = df['PS'].shift(1)\n",
    "df['T2M_lag_1'] = df['T2M'].shift(1)\n",
    "df['RH2M_lag_1'] = df['RH2M'].shift(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75501daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Wind_Power_Density'\n",
    "y = df[target_variable]\n",
    "\n",
    "season_cols = [col for col in df.columns if col.startswith(\"Season_\")]\n",
    "\n",
    "X = df[['Latitude', 'Longitude',\n",
    "        'PS', 'PS_lag_1', \n",
    "        'T2M', 'T2M_lag_1',\n",
    "        'RH2M', 'RH2M_lag_1',\n",
    "        'PRECTOTCORR', 'ALLSKY_SFC_SW_DWN','WS50M'] + season_cols]\n",
    "\n",
    "print(f\"Target (y): {target_variable}\")\n",
    "print(f\"Final Feature Set (X): {list(X.columns)}\")\n",
    "\n",
    "# Log-transform target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Chronological Split\n",
    "test_size = 0.2\n",
    "split_index = int(len(df) * (1 - test_size))\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_train_log = y_log.iloc[:split_index]\n",
    "y_test_log = y_log.iloc[split_index:]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.6548230739520089\n",
      "MAE: 0.018151701030491997\n",
      "RMSE: 0.03366517441798998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"R² Score:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a181f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.6548227221816256\n",
      "MAE: 0.018151661197894804\n",
      "RMSE: 0.033665191572103424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Results ===\n",
      "R²: 0.9828358095590805\n",
      "MAE: 0.003021613568205827\n",
      "RMSE: 0.007507090521815956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== Decision Tree Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e61a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gradient Boosting Results ===\n",
      "R²: 0.986193166314309\n",
      "MAE: 0.0032963245045991908\n",
      "RMSE: 0.006732975546882781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== Gradient Boosting Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac44191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2373\n",
      "[LightGBM] [Info] Number of data points in the train set: 105205, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 0.027132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "=== LightGBM Results ===\n",
      "R²: 0.8866256933022753\n",
      "MAE: 0.008092697185892662\n",
      "RMSE: 0.01929377957730708\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = LGBMRegressor(num_leaves=4,max_depth=1,n_estimators=20,learning_rate=0.5)\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== LightGBM Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ExtraTrees Regression Results ===\n",
      "R²: 0.9926692647598984\n",
      "MAE: 0.0020747814814386215\n",
      "RMSE: 0.00490607019565892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = ExtraTreesRegressor(random_state=42)\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== ExtraTrees Regression Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccda7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVR Results ===\n",
      "R²: 0.318343611183294\n",
      "MAE: 0.03869460946127281\n",
      "RMSE: 0.04730888856205982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = SVR(kernel='rbf')  \n",
    "model.fit(X_train, y_train_log)\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== SVR Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Regression Results ===\n",
      "R²: 0.6601116081415074\n",
      "MAE: 0.013443992504223647\n",
      "RMSE: 0.03340628306004892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "model=model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"=== KNN Regression Results ===\")\n",
    "print(\"R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb5c680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging R²: 0.9889027514450502\n",
      "MAE: 0.002291183363516087\n",
      "RMSE: 0.00603625595925786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "model = BaggingRegressor()\n",
    "\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_test_orig = np.expm1(y_test_log)\n",
    "\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
    "\n",
    "print(\"Bagging R²:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
