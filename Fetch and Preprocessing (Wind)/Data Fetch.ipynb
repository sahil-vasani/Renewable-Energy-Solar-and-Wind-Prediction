{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0a019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Andhra Pradesh...\n",
      "Successfully saved Andhra Pradesh_raw.csv\n",
      "Fetching data for Arunachal Pradesh...\n",
      "Successfully saved Arunachal Pradesh_raw.csv\n",
      "Fetching data for Assam...\n",
      "Successfully saved Assam_raw.csv\n",
      "Fetching data for Bihar...\n",
      "Successfully saved Bihar_raw.csv\n",
      "Fetching data for Chhattisgarh...\n",
      "Successfully saved Chhattisgarh_raw.csv\n",
      "Fetching data for Goa...\n",
      "Successfully saved Goa_raw.csv\n",
      "Fetching data for Gujarat...\n",
      "Successfully saved Gujarat_raw.csv\n",
      "Fetching data for Haryana...\n",
      "Successfully saved Haryana_raw.csv\n",
      "Fetching data for Himachal Pradesh...\n",
      "Successfully saved Himachal Pradesh_raw.csv\n",
      "Fetching data for Jharkhand...\n",
      "Successfully saved Jharkhand_raw.csv\n",
      "Fetching data for Karnataka...\n",
      "Successfully saved Karnataka_raw.csv\n",
      "Fetching data for Kerala...\n",
      "Successfully saved Kerala_raw.csv\n",
      "Fetching data for Madhya Pradesh...\n",
      "Successfully saved Madhya Pradesh_raw.csv\n",
      "Fetching data for Maharashtra...\n",
      "Successfully saved Maharashtra_raw.csv\n",
      "Fetching data for Manipur...\n",
      "Successfully saved Manipur_raw.csv\n",
      "Fetching data for Meghalaya...\n",
      "Successfully saved Meghalaya_raw.csv\n",
      "Fetching data for Mizoram...\n",
      "Successfully saved Mizoram_raw.csv\n",
      "Fetching data for Nagaland...\n",
      "Successfully saved Nagaland_raw.csv\n",
      "Fetching data for Odisha...\n",
      "Successfully saved Odisha_raw.csv\n",
      "Fetching data for Punjab...\n",
      "Successfully saved Punjab_raw.csv\n",
      "Fetching data for Rajasthan...\n",
      "Successfully saved Rajasthan_raw.csv\n",
      "Fetching data for Sikkim...\n",
      "Successfully saved Sikkim_raw.csv\n",
      "Fetching data for Tamil Nadu...\n",
      "Successfully saved Tamil Nadu_raw.csv\n",
      "Fetching data for Telangana...\n",
      "Successfully saved Telangana_raw.csv\n",
      "Fetching data for Tripura...\n",
      "Successfully saved Tripura_raw.csv\n",
      "Fetching data for Uttar Pradesh...\n",
      "Successfully saved Uttar Pradesh_raw.csv\n",
      "Fetching data for Uttarakhand...\n",
      "Successfully saved Uttarakhand_raw.csv\n",
      "Fetching data for West Bengal...\n",
      "Successfully saved West Bengal_raw.csv\n",
      "Fetching data for Andaman and Nicobar Islands...\n",
      "Successfully saved Andaman and Nicobar Islands_raw.csv\n",
      "Fetching data for Chandigarh...\n",
      "Successfully saved Chandigarh_raw.csv\n",
      "Fetching data for Dadra and Nagar Haveli and Daman and Diu...\n",
      "Successfully saved Dadra and Nagar Haveli and Daman and Diu_raw.csv\n",
      "Fetching data for Delhi...\n",
      "Successfully saved Delhi_raw.csv\n",
      "Fetching data for Jammu and Kashmir...\n",
      "Successfully saved Jammu and Kashmir_raw.csv\n",
      "Fetching data for Ladakh...\n",
      "Successfully saved Ladakh_raw.csv\n",
      "Fetching data for Lakshadweep...\n",
      "Successfully saved Lakshadweep_raw.csv\n",
      "Fetching data for Puducherry...\n",
      "Successfully saved Puducherry_raw.csv\n",
      "Data fetching complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# 1. Define your list of states and their central coordinates\n",
    "states_to_fetch = [\n",
    "    {\"name\": \"Andhra Pradesh\", \"lat\": 16.5062, \"lon\": 80.6480},\n",
    "    {\"name\": \"Arunachal Pradesh\", \"lat\": 27.1004, \"lon\": 93.6056},\n",
    "    {\"name\": \"Assam\", \"lat\": 26.1445, \"lon\": 91.7362},\n",
    "    {\"name\": \"Bihar\", \"lat\": 25.5941, \"lon\": 85.1376},\n",
    "    {\"name\": \"Chhattisgarh\", \"lat\": 21.2514, \"lon\": 81.6296},\n",
    "    {\"name\": \"Goa\", \"lat\": 15.4909, \"lon\": 73.8278},\n",
    "    {\"name\": \"Gujarat\", \"lat\": 23.2156, \"lon\": 72.6369},\n",
    "    {\"name\": \"Haryana\", \"lat\": 30.7333, \"lon\": 76.7794},\n",
    "    {\"name\": \"Himachal Pradesh\", \"lat\": 31.1048, \"lon\": 77.1734},\n",
    "    {\"name\": \"Jharkhand\", \"lat\": 23.3441, \"lon\": 85.3096},\n",
    "    {\"name\": \"Karnataka\", \"lat\": 12.9716, \"lon\": 77.5946},\n",
    "    {\"name\": \"Kerala\", \"lat\": 8.5241, \"lon\": 76.9366},\n",
    "    {\"name\": \"Madhya Pradesh\", \"lat\": 23.2599, \"lon\": 77.4126},\n",
    "    {\"name\": \"Maharashtra\", \"lat\": 19.0760, \"lon\": 72.8777},\n",
    "    {\"name\": \"Manipur\", \"lat\": 24.8170, \"lon\": 93.9368},\n",
    "    {\"name\": \"Meghalaya\", \"lat\": 25.5788, \"lon\": 91.8933},\n",
    "    {\"name\": \"Mizoram\", \"lat\": 23.7367, \"lon\": 92.7176},\n",
    "    {\"name\": \"Nagaland\", \"lat\": 25.6751, \"lon\": 94.1086},\n",
    "    {\"name\": \"Odisha\", \"lat\": 20.2961, \"lon\": 85.8245},\n",
    "    {\"name\": \"Punjab\", \"lat\": 30.7333, \"lon\": 76.7794},\n",
    "    {\"name\": \"Rajasthan\", \"lat\": 26.9124, \"lon\": 75.7873},\n",
    "    {\"name\": \"Sikkim\", \"lat\": 27.3389, \"lon\": 88.6065},\n",
    "    {\"name\": \"Tamil Nadu\", \"lat\": 13.0827, \"lon\": 80.2707},\n",
    "    {\"name\": \"Telangana\", \"lat\": 17.3850, \"lon\": 78.4867},\n",
    "    {\"name\": \"Tripura\", \"lat\": 23.8315, \"lon\": 91.2868},\n",
    "    {\"name\": \"Uttar Pradesh\", \"lat\": 26.8467, \"lon\": 80.9462},\n",
    "    {\"name\": \"Uttarakhand\", \"lat\": 30.3165, \"lon\": 78.0322},\n",
    "    {\"name\": \"West Bengal\", \"lat\": 22.5726, \"lon\": 88.3639},\n",
    "    {\"name\": \"Andaman and Nicobar Islands\", \"lat\": 11.6234, \"lon\": 92.7265},\n",
    "    {\"name\": \"Chandigarh\", \"lat\": 30.7333, \"lon\": 76.7794},\n",
    "    {\"name\": \"Dadra and Nagar Haveli and Daman and Diu\", \"lat\": 20.4283, \"lon\": 72.8397},\n",
    "    {\"name\": \"Delhi\", \"lat\": 28.6139, \"lon\": 77.2090},\n",
    "    {\"name\": \"Jammu and Kashmir\", \"lat\": 34.0837, \"lon\": 74.7973},\n",
    "    {\"name\": \"Ladakh\", \"lat\": 34.1526, \"lon\": 77.5771},\n",
    "    {\"name\": \"Lakshadweep\", \"lat\": 10.5667, \"lon\": 72.6417},\n",
    "    {\"name\": \"Puducherry\", \"lat\": 11.9416, \"lon\": 79.8083}\n",
    "]\n",
    "\n",
    "# 2. Define the API parameters you want from NASA\n",
    "api_parameters = [\n",
    "    # Components to create your target\n",
    "    'WS10M',\n",
    "    'WS50M',         \n",
    "    'PS',            \n",
    "    'T2M',           \n",
    "    'WD10M',\n",
    "    'T2M_MAX',\n",
    "    'T2M_MIN',\n",
    "    'T2MDEW',\n",
    "    'RH2M',\n",
    "    'PRECTOTCORR',\n",
    "    'ALLSKY_SFC_SW_DWN'\n",
    "]\n",
    "\n",
    "# 3. Define the base URL and other settings\n",
    "base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "start_date = \"20150101\"\n",
    "end_date = \"20241231\"\n",
    "\n",
    "# 4. Loop, Fetch, and Save\n",
    "for state in states_to_fetch:\n",
    "    print(f\"Fetching data for {state['name']}...\")\n",
    "    \n",
    "    params = {\n",
    "        \"parameters\": \",\".join(api_parameters),\n",
    "        \"community\": \"RE\",\n",
    "        \"longitude\": state['lon'],\n",
    "        \"latitude\": state['lat'],\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"CSV\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, timeout=30) # Added timeout\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # The CSV data starts after a header, find the start of the data\n",
    "            content = response.text\n",
    "            data_start_index = content.find(\"YEAR,MO,DY\")\n",
    "            \n",
    "            if data_start_index != -1:\n",
    "                # Read the CSV data into a pandas DataFrame\n",
    "                csv_data = content[data_start_index:]\n",
    "                df = pd.read_csv(io.StringIO(csv_data))\n",
    "                \n",
    "                # Check if DataFrame is empty (can happen for bad date ranges/params)\n",
    "                if df.empty:\n",
    "                    print(f\"No data returned for {state['name']}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Create the 'Date' column\n",
    "                df['Date'] = pd.to_datetime(df[['YEAR', 'MO', 'DY']].astype(str).agg('-'.join, axis=1))\n",
    "                \n",
    "                # Add state and coordinate columns\n",
    "                df['State'] = state['name']\n",
    "                df['Latitude'] = state['lat']\n",
    "                df['Longitude'] = state['lon']\n",
    "                \n",
    "                # Clean up and reorder columns\n",
    "                df = df.drop(columns=['YEAR', 'MO', 'DY'])\n",
    "                cols_to_move = ['Date', 'State', 'Latitude', 'Longitude']\n",
    "                df = df[cols_to_move + [col for col in df.columns if col not in cols_to_move]]\n",
    "                \n",
    "                # Save the raw CSV file\n",
    "                filename = f\"{state['name']}_raw.csv\"\n",
    "                df.to_csv(filename, index=False)\n",
    "                print(f\"Successfully saved {filename}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Could not parse CSV data for {state['name']}. Response: {content}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Error fetching data for {state['name']}. Status Code: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Request for {state['name']} timed out. Skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {state['name']}: {e}\")\n",
    "\n",
    "print(\"Data fetching complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0987990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 files to merge. Starting merge process...\n",
      "  - Added Andaman and Nicobar Islands_raw.csv (3653 rows)\n",
      "  - Added Andhra Pradesh_raw.csv (3653 rows)\n",
      "  - Added Arunachal Pradesh_raw.csv (3653 rows)\n",
      "  - Added Assam_raw.csv (3653 rows)\n",
      "  - Added Bihar_raw.csv (3653 rows)\n",
      "  - Added Chandigarh_raw.csv (3653 rows)\n",
      "  - Added Chhattisgarh_raw.csv (3653 rows)\n",
      "  - Added Dadra and Nagar Haveli and Daman and Diu_raw.csv (3653 rows)\n",
      "  - Added Delhi_raw.csv (3653 rows)\n",
      "  - Added Goa_raw.csv (3653 rows)\n",
      "  - Added Gujarat_raw.csv (3653 rows)\n",
      "  - Added Haryana_raw.csv (3653 rows)\n",
      "  - Added Himachal Pradesh_raw.csv (3653 rows)\n",
      "  - Added Jammu and Kashmir_raw.csv (3653 rows)\n",
      "  - Added Jharkhand_raw.csv (3653 rows)\n",
      "  - Added Karnataka_raw.csv (3653 rows)\n",
      "  - Added Kerala_raw.csv (3653 rows)\n",
      "  - Added Ladakh_raw.csv (3653 rows)\n",
      "  - Added Lakshadweep_raw.csv (3653 rows)\n",
      "  - Added Madhya Pradesh_raw.csv (3653 rows)\n",
      "  - Added Maharashtra_raw.csv (3653 rows)\n",
      "  - Added Manipur_raw.csv (3653 rows)\n",
      "  - Added Meghalaya_raw.csv (3653 rows)\n",
      "  - Added Mizoram_raw.csv (3653 rows)\n",
      "  - Added Nagaland_raw.csv (3653 rows)\n",
      "  - Added Odisha_raw.csv (3653 rows)\n",
      "  - Added Puducherry_raw.csv (3653 rows)\n",
      "  - Added Punjab_raw.csv (3653 rows)\n",
      "  - Added Rajasthan_raw.csv (3653 rows)\n",
      "  - Added Sikkim_raw.csv (3653 rows)\n",
      "  - Added Tamil Nadu_raw.csv (3653 rows)\n",
      "  - Added Telangana_raw.csv (3653 rows)\n",
      "  - Added Tripura_raw.csv (3653 rows)\n",
      "  - Added Uttar Pradesh_raw.csv (3653 rows)\n",
      "  - Added Uttarakhand_raw.csv (3653 rows)\n",
      "  - Added West Bengal_raw.csv (3653 rows)\n",
      "\n",
      "MERGE COMPLETE! \n",
      "Total rows in master dataset:131508\n",
      "Saved master file to:d:\\DAU\\ASSIGNMENT\\FOML ASSIGN\\PROJ\\SAHIL\\India_Renewable_Energy_MASTER_DATASET222.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. Define the pattern for the files you want to merge\n",
    "file_pattern = '*_raw.csv'\n",
    "output_filename = 'India_Renewable_Energy_MASTER_DATASET222.csv'\n",
    "\n",
    "# 2. Use glob to find all files matching the pattern\n",
    "all_files = glob.glob(file_pattern)\n",
    "\n",
    "# Check if any files were found\n",
    "if not all_files:\n",
    "    print(f\"Error: No files found matching the pattern '{file_pattern}'.\")\n",
    "else:\n",
    "    # 3. Read each file and store its DataFrame in a list\n",
    "    dataframes_list = []\n",
    "    print(f\"Found {len(all_files)} files to merge. Starting merge process...\")\n",
    "    \n",
    "    for filename in all_files:\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(filename)\n",
    "            dataframes_list.append(df)\n",
    "            print(f\"  - Added {filename} ({len(df)} rows)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error reading {filename}: {e}. Skipping this file.\")\n",
    "\n",
    "    # 4. Concatenate all DataFrames into one master DataFrame\n",
    "    if dataframes_list:\n",
    "        master_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "        \n",
    "        # 5. Sort the master DataFrame by State and Date for clean analysis\n",
    "        master_df['Date'] = pd.to_datetime(master_df['Date'])\n",
    "        master_df = master_df.sort_values(by=['State', 'Date']).reset_index(drop=True)\n",
    "        \n",
    "        # 6. Save the final master file\n",
    "        master_df.to_csv(output_filename, index=False)\n",
    "        \n",
    "        print(\"\\nMERGE COMPLETE! \")\n",
    "        print(f\"Total rows in master dataset:{len(master_df)}\")\n",
    "        print(f\"Saved master file to:{os.path.abspath(output_filename)}\")\n",
    "    else:\n",
    "        print(\"No DataFrames were successfully loaded, so no master file was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c925df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded master file 'India_Renewable_Energy_MASTER_DATASET222.csv' with 131508 rows.\n",
      "Calculating Air_Density...\n",
      "   -> Column 'Air_Density' created.\n",
      "Calculating Wind_Power_Density...\n",
      "   -> Column 'Wind_Power_Density' created.\n",
      "\n",
      "✨ **Feature Engineering Complete!** ✨\n",
      "Updated dataset with new calculations saved as: **India_Renewable_Energy_MASTER_DATASET_Calculated.csv**\n",
      "\n",
      "Final column information after updates:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131508 entries, 0 to 131507\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Date                131508 non-null  object \n",
      " 1   State               131508 non-null  object \n",
      " 2   Latitude            131508 non-null  float64\n",
      " 3   Longitude           131508 non-null  float64\n",
      " 4   WS10M               131508 non-null  float64\n",
      " 5   WS50M               131508 non-null  float64\n",
      " 6   PS                  131508 non-null  float64\n",
      " 7   T2M                 131508 non-null  float64\n",
      " 8   WD10M               131508 non-null  float64\n",
      " 9   T2M_MAX             131508 non-null  float64\n",
      " 10  T2M_MIN             131508 non-null  float64\n",
      " 11  T2MDEW              131508 non-null  float64\n",
      " 12  RH2M                131508 non-null  float64\n",
      " 13  PRECTOTCORR         131508 non-null  float64\n",
      " 14  ALLSKY_SFC_SW_DWN   131508 non-null  float64\n",
      " 15  Air_Density         131508 non-null  float64\n",
      " 16  Wind_Power_Density  131508 non-null  float64\n",
      "dtypes: float64(15), object(2)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba5845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
